{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cb81f54f-e4e4-42ab-8dd7-609243a21793",
   "metadata": {},
   "source": [
    "{{title_s1_5}}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de8ae299-26ac-4401-b0ad-bb817e327b6f",
   "metadata": {},
   "source": [
    "So far in this tutorial, we've demonstrated how to read Sentinel-1 RTC imagery from two sources and assemble analysis-ready data cubes with appropriate metadata. Now, we'll perform a comparison of the two datasets. \n",
    "\n",
    "::::{tab-set}\n",
    ":::{tab-item} Dataset comparison\n",
    "\n",
    "While the two datasets are very similar, there are a few key differences:  \n",
    "1) They use different sources images.   \n",
    "    - ASF Sentinel-1 RTC imagery is processed from Single Look Complex ([SLC](https://sentinels.copernicus.eu/web/sentinel/technical-guides/sentinel-1-sar/products-algorithms/level-1-algorithms/single-look-complex)) images while Planetary Computer Sentinel-1 RTC imagery is processed from Ground Range Detected ([GRD](https://sentinels.copernicus.eu/web/sentinel/technical-guides/sentinel-1-sar/products-algorithms/level-1-algorithms/ground-range-detected)) images. SLC images contain both amplitude and phase information for each pixel. They are in radar coordinates and have not yet been multi-looked. In contrast, GRD images has been detected, multi-looked and projected to ground range.\n",
    "\n",
    "2) They use different digital elevation models (DEMs) for terrain correction.  \n",
    "    - ASF uses the [GLO-30 Copernicus DEM](https://dataspace.copernicus.eu/explore-data/data-collections/copernicus-contributing-missions/collections-description/COP-DEM) while Planetary Computer uses a Planet DEM.  \n",
    "3) The datasets have different pixel spacings. For Planetary Computer, the pixel spacing is 10m in both range and azimuth directions. ASF has the option to produce images with 30 m, 20 m, or 10 m pixel spacing. The data used in this tutorial is 30 m. Note that there are tradeoffs in processing time and file size with pixel spacing, see more discussion [here](https://hyp3-docs.asf.alaska.edu/guides/rtc_product_guide/#pixel-spacing_1).  \n",
    "4) Each platform uses a different algorithm for RTC processing.\n",
    "5) The ASF dataset comes with an associated layover shadow map for each scene while the Planetary Computer dataset does not.  \n",
    "\n",
    "All of the above information and much more detail about the processing methods for both datasets are available in each dataset's documentation pages:\n",
    "- [ASF Sentinel-1 RTC Product Guide](https://hyp3-docs.asf.alaska.edu/guides/rtc_product_guide/#pixel-spacing_1)  \n",
    "- [Microsoft Planetary Computer Sentinel-1 RTC dataset](https://planetarycomputer.microsoft.com/dataset/sentinel-1-rtc) \n",
    "::: \n",
    "\n",
    ":::{tab-item} Outline\n",
    "\n",
    "(content.Section_A)=\n",
    "**[A. Read and prepare data](#a-read-and-prepare-data)**  \n",
    "- {{a1_s1_nb5}}  \n",
    "\n",
    "(content.Section_B)=\n",
    "**[B. Ensure direct comparison between datasets](#b-ensure-direct-comparison-between-datasets)**\n",
    "- {{b1_s1_nb5}}\n",
    "- {{b2_s1_nb5}}\n",
    "- {{b3_s1_nb5}}\n",
    "\n",
    "(content.Section_C)=\n",
    "**[C. Combine objects](#c-combine-objects)**\n",
    "- {{c1_s1_nb5}}\n",
    "- {{c2_s1_nb5}}\n",
    "\n",
    "(content.Section_D)=\n",
    "**[D. Visualize comparisons](#d-visualize-comparisons)**\n",
    "- {{d1_s1_nb5}}\n",
    "- {{d2_s1_nb5}}\n",
    "\n",
    ":::\n",
    ":::{tab-item} Learning goals\n",
    "\n",
    "{{concepts}}\n",
    "- Comparing and evaluating multiple datasets\n",
    "- Organizing data so that its structure matches your use-case\n",
    "\n",
    "{{techniques}}\n",
    "- Conditional selection based on non-dimensional coordinates using `xr.Dataset.where()`\n",
    "- Subsetting datasets based on dimensional coordinates using `xr.DataArray.isin()`\n",
    "- Adding dimensional and non-dimensional coordinates to `xr.Dataset` objects\n",
    "- Xarray plotting methods\n",
    "- Projecting xarray objects to different grids using `xr.interp_like()`\n",
    ":::\n",
    "::::\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b7dfad4-f399-4ad1-b733-1f6eb04ceefc",
   "metadata": {
    "tags": [
     "hide-input",
     "hide-output"
    ]
   },
   "outputs": [],
   "source": [
    "# %xmode minimal\n",
    "import hvplot.xarray\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "import warnings\n",
    "\n",
    "import s1_tools\n",
    "\n",
    "warnings.simplefilter(action=\"ignore\", category=FutureWarning)\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b86c0bba",
   "metadata": {},
   "source": [
    "{{break}}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a37accb-b1af-4048-b365-616c48d8ebb5",
   "metadata": {},
   "source": [
    "## A. Read and prepare data\n",
    "\n",
    "At the end of notebook 3, we wrote the analysis-ready ASF Sentinel-1 data cube that had been clipped to a smaller spatial area of interest to disk. We'll read that into memory now to use in this comparison.\n",
    "\n",
    "We used Jupyter cell magic to persist the Planetary Computer data cube created in notebook 4. Now we can read it into our notebook by adding `-r` to the store magic command used to persist it. Read more about `storemagic` [here](https://ipython.readthedocs.io/en/stable/config/extensions/storemagic.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31904346",
   "metadata": {},
   "outputs": [],
   "source": [
    "%store -r da\n",
    "pc_cube = da"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3c4a573",
   "metadata": {},
   "outputs": [],
   "source": [
    "pc_cube = pc_cube.compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63bb8f60",
   "metadata": {},
   "outputs": [],
   "source": [
    "timeseries_type = \"full\"\n",
    "\n",
    "asf_cube = xr.open_dataset(\n",
    "    f\"../data/raster_data/{timeseries_type}_timeseries/intermediate_cubes/s1_asf_clipped_cube.zarr\",\n",
    "    engine=\"zarr\",\n",
    "    chunks=\"auto\",\n",
    "    decode_coords=\"all\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d502a084",
   "metadata": {},
   "source": [
    "Rename the temporal dimension of the ASF dataset to match that of the PC dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85c0d65d",
   "metadata": {},
   "outputs": [],
   "source": [
    "asf_cube = asf_cube.rename({\"acq_date\": \"time\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "090d61ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "asf_cube = asf_cube.compute()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86b3a6e1",
   "metadata": {},
   "source": [
    "### {{a1_s1_nb5}}\n",
    "\n",
    "First, make sure that both objects are projected to the same CRS."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dade7c38",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert pc_cube.rio.crs == asf_cube.rio.crs, \"CRS of both data cubes are expected to be identical.\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "343285c9",
   "metadata": {},
   "source": [
    "Let's also check how missing data is handled in both objects. We want missing data to be assigned NaN values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c3e4da8",
   "metadata": {},
   "outputs": [],
   "source": [
    "asf_cube[\"vv\"].rio.nodata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94053f7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "pc_cube.sel(band=\"vv\").rio.nodata"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfec6386",
   "metadata": {},
   "source": [
    "The `pc_cube` array contains nan values, but it doesn't have an encoding specifying what value is used to represent nodata. We can assign a nodata value to the dataset below. See Rioxarray's [Nodata Management documentation](https://corteva.github.io/rioxarray/stable/getting_started/nodata_management.html) for more detail on this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c341ff7",
   "metadata": {},
   "outputs": [],
   "source": [
    "pc_cube.rio.write_nodata(np.nan, inplace=True)\n",
    "pc_cube.rio.nodata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2a90545",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert (\n",
    "    np.isnan(asf_cube.vh.rio.nodata) == np.isnan(pc_cube.sel(band=\"vh\").rio.nodata) == True\n",
    "), \"Expected vh nodata value to be np.nan\"\n",
    "assert (\n",
    "    np.isnan(asf_cube.vv.rio.nodata) == np.isnan(pc_cube.sel(band=\"vv\").rio.nodata) == True\n",
    "), \"Expected vv nodata value to be np.nan\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf41736f",
   "metadata": {},
   "source": [
    "## B. Ensure direct comparison between datasets\n",
    "\n",
    "In notebook 3, we removed time steps from the ASF time series where the area of interest was only partially covered by the satellite footprint. Let's do the same for the PC dataset: \n",
    "\n",
    "Thanks to all of the metadata wrangling we did in earlier notebooks, we can quickly access information needed to ensure a direct comparison of time steps between the two datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1181668",
   "metadata": {},
   "source": [
    "### {{b1_s1_nb5}}\n",
    "\n",
    "Make a list of the acquisition dates in the ASF time series:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d507c285",
   "metadata": {},
   "outputs": [],
   "source": [
    "asf_acq_dates = asf_cube.time.dt.date.data.tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8a46905",
   "metadata": {},
   "source": [
    "Subset the PC time series to only the time steps that exist in the ASF time series:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b6d1f93",
   "metadata": {},
   "outputs": [],
   "source": [
    "pc_subset = pc_cube.where(pc_cube.time.dt.date.isin(asf_acq_dates), drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c675fe42",
   "metadata": {},
   "source": [
    "Make sure that the time steps we're excluding only have partial coverage:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61cc5be9",
   "metadata": {},
   "outputs": [],
   "source": [
    "pc_outtakes = (\n",
    "    pc_cube.where(~pc_cube.time.dt.date.isin(asf_acq_dates), drop=True).to_dataset(dim=\"band\").drop_dims(\"band\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b320e1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_pixels = pc_outtakes.mean(dim=\"time\").x.shape[0] * pc_outtakes.mean(dim=\"time\").y.shape[0]\n",
    "valid_pixels = pc_outtakes.vv.count(dim=[\"x\", \"y\"])\n",
    "pc_outtakes[\"cov\"] = (valid_pixels / max_pixels) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45dfbe3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(12, 4))\n",
    "pc_outtakes.cov.plot.scatter(x=\"time\", y=\"cov\", ax=ax)\n",
    "ax.set_ylabel(\"Coverage (%)\")\n",
    "ax.set_title(\"None\")\n",
    "fig.suptitle(\"% Coverage of excluded time steps\");\n",
    "# ax.set_ylim(0,100);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1156615d",
   "metadata": {},
   "source": [
    "Great, we've successfully removed the time steps with limited coverage. Make sure that the time steps of the two datasets are now identical:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a21d6a03",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.testing.assert_array_equal(asf_cube.time.dt.date.data, pc_subset.time.dt.date.data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cb87a14",
   "metadata": {},
   "source": [
    "Now that we know we are looking at the same time steps across the two datasets, let's take a look at the data for a few individual scenes side-by-side to get a better image of the differences still remaining between the two data cubes. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64d915a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(ncols=3, nrows=2, figsize=(12, 5), layout=\"constrained\")\n",
    "\n",
    "backscatter_kwargs = {\"cmap\": \"Greys_r\", \"cbar_kwargs\": {\"label\": \"dB\"}}\n",
    "ls_kwargs = {\n",
    "    \"cmap\": \"tab20b\",\n",
    "    \"vmin\": 0,\n",
    "    \"vmax\": 32,\n",
    "    \"cbar_kwargs\": {\"label\": \"layover-shadow map\"},\n",
    "}\n",
    "\n",
    "s1_tools.power_to_db(pc_subset.isel(time=1).sel(band=\"vv\")).plot(ax=axs[0][0], **backscatter_kwargs)\n",
    "s1_tools.power_to_db(asf_cube.isel(time=1)).vv.plot(ax=axs[0][1], **backscatter_kwargs)\n",
    "asf_cube.isel(time=1).ls.plot(ax=axs[0][2], **ls_kwargs)\n",
    "\n",
    "s1_tools.power_to_db(pc_subset.isel(time=10).sel(band=\"vv\")).plot(ax=axs[1][0], **backscatter_kwargs)\n",
    "s1_tools.power_to_db(asf_cube.isel(time=10)).vv.plot(ax=axs[1][1], **backscatter_kwargs)\n",
    "asf_cube.isel(time=10).ls.plot(ax=axs[1][2], **ls_kwargs)\n",
    "\n",
    "col_names = [\"PC backscatter\", \"ASF backscatter\", \"ASF layover-shadow map\"]\n",
    "\n",
    "for i in range(axs.shape[0]):\n",
    "    for j in range(axs.shape[1]):\n",
    "        if i == 0:\n",
    "            axs[i, j].set_title(col_names[j])\n",
    "        else:\n",
    "            axs[i, j].set_title(None)\n",
    "\n",
    "        axs[i, j].tick_params(axis=\"x\", labelrotation=45)\n",
    "        axs[i, j].set_ylabel(None)\n",
    "        axs[i, j].set_xlabel(None)\n",
    "\n",
    "fig.supylabel(\"Y coordinate of projection (m)\", x=-0.05)\n",
    "fig.supxlabel(\"X coordinate of projection (m)\", y=-0.10)\n",
    "fig.suptitle(\n",
    "    f\"Comparing PC (left), ASF (center) backscatter images at two time steps: \\n {asf_cube.isel(time=1).time.dt.date.data.astype(str)} (top) and {asf_cube.isel(time=10).time.dt.date.data.astype(str)} (bottom) \\n Right column shows ASF layover-shadow map\",\n",
    "    fontsize=14,\n",
    "    y=1.15,\n",
    ");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e42e521d",
   "metadata": {},
   "source": [
    "As discussed at the top of this notebook, the PC dataset has a higher spatial resolution than the ASF dataset. The ASF dataset masks pixels that are in radar shadow on the associated layover-shadow map. The PC dataset does not mask out pixels in the same way the the ASF dataset does. It appears that many pixels near the masked regions in the ASF dataset are very dark, and that they are smaller than the shadow regions in the ASF images, which makes sense given the higher spatial resolution. \n",
    "\n",
    "To compare the two backscatter datasets, we need to align them on a common spatial grid and apply the same mask that the ASF dataset has to the PC dataset. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0bfe59f",
   "metadata": {},
   "source": [
    "### {{b2_s1_nb5}}\n",
    "\n",
    "Different approaches to regrid the dataset exist. Here, we will use `xr.interp_like()`. For more discussion and examples of regridding approaches with Xarray, we recommend the Project Pythia Cookbook, [*(re)Gridding with Xarray*](https://projectpythia.org/gridding-cookbook/README.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcc9996d",
   "metadata": {},
   "outputs": [],
   "source": [
    "asf_da = asf_cube.to_dataarray(dim=\"band\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63bff3ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "pc_downsample = pc_subset.interp_like(asf_da)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10b75c89",
   "metadata": {},
   "source": [
    "Check that the x and y dimensions of the ASF and PC datasets are the same:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e148c664",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert set(asf_da.shape) == set(pc_downsample.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3f668c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We don't use xr.da.equals() because the coords are not the same\n",
    "np.testing.assert_array_equal(asf_da.x.data, pc_downsample.x.data)\n",
    "np.testing.assert_array_equal(asf_da.y.data, pc_downsample.y.data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3c8437f-8771-412c-aacf-1d4c69cd4658",
   "metadata": {},
   "source": [
    "Take a look at the downsampled object:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c50301ed-a01e-45cc-ab08-eb45f552c7ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "pc_downsample"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "919b407d-7b3b-41bc-8624-0d6b019875b5",
   "metadata": {},
   "source": [
    "`xr.interp_like()` interpolates the values from the PC dataset (`pc_subset`) onto the grid of `asf_da`. Notice that, while the resultant object has the expected dimensions, the band dimension is not indexed. To fix this, use [`xr.set_index()`](https://docs.xarray.dev/en/stable/generated/xarray.Dataset.set_index.html) to create an index from the `band` coordinate variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abe44cad-4d8a-4856-8e5a-e0c4eeaf0469",
   "metadata": {},
   "outputs": [],
   "source": [
    "pc_downsample = pc_downsample.set_index(band='band')\n",
    "pc_downsample"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99d8ea31",
   "metadata": {},
   "source": [
    "Great, now the data are aligned on the same spatial grid with proper indexes, but we still need to mask the data in the PC dataset categorized as 'shadow' in the ASF dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecac89a5",
   "metadata": {},
   "source": [
    "### {{b3_s1_nb5}}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f17111a9",
   "metadata": {},
   "source": [
    "We'll use [`xr.where()`](https://docs.xarray.dev/en/stable/generated/xarray.where.html) to assign NaN to all pixels in the PC dataset where the corresponding pixel in the ASF dataset is NaN:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63ee3ebd",
   "metadata": {},
   "outputs": [],
   "source": [
    "pc_mask = xr.where(asf_da.notnull(), pc_downsample, np.nan)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3913ac05",
   "metadata": {},
   "source": [
    "Let's check that the masking operation did what we expect it to do:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "471d2ecf",
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(ncols=2, figsize=(12, 4))\n",
    "\n",
    "date_target = \"2021-12-2\"\n",
    "date_actual = asf_da.sel(time=date_target, method=\"nearest\").time.dt.date.data.astype(str)\n",
    "fig.suptitle(f\"{date_actual}: Comparing backscatter images \" + r\"$\\bf{before}$\" + \" masking\")\n",
    "s1_tools.power_to_db(asf_da.sel(band=\"vv\").sel(time=date_target, method=\"nearest\")).plot(cmap=plt.cm.Greys_r, ax=ax[0])\n",
    "ax[0].set_title(\"ASF\")\n",
    "s1_tools.power_to_db(pc_downsample.sel(band=\"vv\").sel(time=date_target, method=\"nearest\")).plot(\n",
    "    cmap=plt.cm.Greys_r, ax=ax[1], cbar_kwargs={\"label\": \"backscatter\"}\n",
    ")\n",
    "ax[1].set_title(\"PC\")\n",
    "\n",
    "ax[0].set_ylabel(None)\n",
    "ax[0].set_xlabel(None)\n",
    "\n",
    "ax[1].set_ylabel(None)\n",
    "ax[1].set_xlabel(None);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a4dc2bf",
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(ncols=2, figsize=(12, 4))\n",
    "\n",
    "date_target = \"2021-12-2\"\n",
    "date_actual = asf_da.sel(time=date_target, method=\"nearest\").time.dt.date.data.astype(str)\n",
    "fig.suptitle(f\"{date_actual}: Comparing backscatter images \" + r\"$\\bf{after}$\" + \" masking\")\n",
    "s1_tools.power_to_db(asf_da.sel(band=\"vv\").sel(time=date_target, method=\"nearest\")).plot(cmap=plt.cm.Greys_r, ax=ax[0])\n",
    "ax[0].set_title(\"ASF\")\n",
    "s1_tools.power_to_db(pc_mask.sel(band=\"vv\").sel(time=date_target, method=\"nearest\")).plot(\n",
    "    cmap=plt.cm.Greys_r, ax=ax[1], cbar_kwargs={\"label\": \"dB\"}\n",
    ")\n",
    "ax[1].set_title(\"PC\")\n",
    "\n",
    "ax[0].set_ylabel(None)\n",
    "ax[0].set_xlabel(None)\n",
    "\n",
    "ax[1].set_ylabel(None)\n",
    "ax[1].set_xlabel(None);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3af65216",
   "metadata": {},
   "source": [
    "## C. Combine objects\n",
    "\n",
    "The two datasets are ready to compare. So far in this book, we've been treating each data cube as an independent unit of analysis containing backscatter data, so it made sense to have dimensions `('x','y','time')` or `('x','y','time','band')`. Now, we're interested in comparing the backscatter values between the two datasets. In effect, this new objective implies a new dimension on the datacube, `'source'`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d87132a0",
   "metadata": {},
   "source": [
    "### {{c1_s1_nb5}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33b488fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "asf_da = asf_da.expand_dims(\"source\")\n",
    "pc_mask = pc_mask.expand_dims(\"source\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e6b037f",
   "metadata": {},
   "outputs": [],
   "source": [
    "asf_da[\"source\"] = (\"source\", [\"asf\"])\n",
    "pc_mask[\"source\"] = (\"source\", [\"pc\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "073f8490",
   "metadata": {},
   "source": [
    "### {{c2_s1_nb5}}\n",
    "\n",
    "Now both datasets can be combined into a single data cube along the `'source'` dimension:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "023d2e5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "comparison_obj = xr.combine_by_coords([asf_da, pc_mask])\n",
    "comparison_obj"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dae6d44",
   "metadata": {},
   "source": [
    "## D. Visualize comparisons"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b6b0bd6",
   "metadata": {},
   "source": [
    "We're ready to visualize backscatter from both datasets. Because we've made a data cube whose dimensionality reflects the comparison, we can use Xarray's plotting features and visualize the comparisons from a single object."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24286470",
   "metadata": {},
   "source": [
    "### {{d1_s1_nb5}}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07b2bd67",
   "metadata": {},
   "source": [
    "Look at VV backscatter first:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8586e43b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot backscatter data\n",
    "vv_fg = s1_tools.power_to_db(comparison_obj.sel(band=\"vv\").mean(dim=\"time\")).plot(\n",
    "    col=\"source\", cmap=plt.cm.Greys_r, cbar_kwargs=({\"label\": \"dB\"})\n",
    ")\n",
    "# Format figure and axes\n",
    "vv_fg.fig.suptitle(\"Comparing VV backscatter from ASF and PC datasets\")\n",
    "vv_fg.fig.supxlabel(\"X coordinate of projection (m)\")\n",
    "vv_fg.fig.supylabel(\"Y coordinate of projection (m)\")\n",
    "vv_fg.fig.set_figheight(7)\n",
    "vv_fg.fig.set_figwidth(12)\n",
    "\n",
    "for i in range(len(vv_fg.axs[0])):\n",
    "    vv_fg.axs[0][i].set_xlabel(None)\n",
    "    vv_fg.axs[0][i].set_ylabel(None)\n",
    "vv_fg.axs[0][0].set_title(\"ASF\")\n",
    "vv_fg.axs[0][1].set_title(\"PC\");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8db463e",
   "metadata": {},
   "source": [
    "Then VH:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1249ef5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot backscatter data\n",
    "vh_fg = s1_tools.power_to_db(comparison_obj.sel(band=\"vh\").mean(dim=\"time\")).plot(\n",
    "    col=\"source\", cmap=plt.cm.Greys_r, cbar_kwargs=({\"label\": \"dB\"})\n",
    ")\n",
    "\n",
    "# Figure and axes formatting\n",
    "vh_fg.fig.suptitle(\"Comparing VH backscatter from ASF and PC datasets\")\n",
    "vh_fg.fig.supxlabel(\"X coordinate of projection (m)\")\n",
    "vh_fg.fig.supylabel(\"Y coordinate of projection (m)\")\n",
    "vh_fg.fig.set_figheight(7)\n",
    "vh_fg.fig.set_figwidth(12)\n",
    "for i in range(len(vh_fg.axs[0])):\n",
    "    vh_fg.axs[0][i].set_xlabel(None)\n",
    "    vh_fg.axs[0][i].set_ylabel(None)\n",
    "vh_fg.axs[0][0].set_title(\"ASF\")\n",
    "vh_fg.axs[0][1].set_title(\"PC\");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0f931b4",
   "metadata": {},
   "source": [
    "### {{d2_s1_nb5}}\n",
    "\n",
    "Instead of computing mean backscatter values along the time dimension, reduce along the spatial dimensions (x and y) to see backscatter variability over time:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e8104ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(nrows=2, figsize=(14, 8), layout=\"constrained\")\n",
    "s1_tools.power_to_db(comparison_obj.sel(source=\"asf\", band=\"vv\").mean(dim=[\"x\", \"y\"])).plot.scatter(\n",
    "    x=\"time\", ax=ax[0], label=\"asf\", c=\"b\", alpha=0.75\n",
    ")\n",
    "s1_tools.power_to_db(comparison_obj.sel(source=\"pc\", band=\"vv\").mean(dim=[\"x\", \"y\"])).plot.scatter(\n",
    "    x=\"time\", ax=ax[0], label=\"pc\", c=\"r\", alpha=0.75\n",
    ")\n",
    "\n",
    "s1_tools.power_to_db(comparison_obj.sel(source=\"asf\", band=\"vh\").mean(dim=[\"x\", \"y\"])).plot.scatter(\n",
    "    x=\"time\", ax=ax[1], label=\"asf\", c=\"b\", alpha=0.75\n",
    ")\n",
    "s1_tools.power_to_db(comparison_obj.sel(source=\"pc\", band=\"vh\").mean(dim=[\"x\", \"y\"])).plot.scatter(\n",
    "    x=\"time\", ax=ax[1], label=\"pc\", c=\"r\", alpha=0.75\n",
    ")\n",
    "ax[0].legend(loc=\"lower right\", bbox_to_anchor=([1, -0.25, 0, 0]))\n",
    "\n",
    "for i in range(len(ax)):\n",
    "    ax[i].set_xlabel(None)\n",
    "    ax[i].set_ylabel(\"dB\")\n",
    "\n",
    "ax[0].set_title(\"VV\")\n",
    "ax[1].set_title(\"VH\")\n",
    "\n",
    "fig.supxlabel(\"Time\")\n",
    "# fig.supylabel('dB')\n",
    "fig.suptitle(\n",
    "    \"Comparing mean VV and VH backscatter over time from PC (red) and ASF (blue) datasets\",\n",
    "    fontsize=14,\n",
    "    y=1.05,\n",
    ");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96456c64",
   "metadata": {},
   "source": [
    "We can also use `hvplot` to make an interactive visualization of this comparison:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75bd8885",
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "asf_plot = s1_tools.power_to_db(\n",
    "    comparison_obj.sel(source=\"asf\").to_dataset(dim=\"band\")[\"vv\"].mean(dim=[\"x\", \"y\"])\n",
    ").hvplot.scatter(x=\"time\", label=\"asf\")\n",
    "pc_plot = s1_tools.power_to_db(\n",
    "    comparison_obj.sel(source=\"pc\").to_dataset(dim=\"band\")[\"vv\"].mean(dim=[\"x\", \"y\"])\n",
    ").hvplot.scatter(x=\"time\", label=\"pc\")\n",
    "\n",
    "asf_plot * pc_plot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7996fd04",
   "metadata": {},
   "source": [
    "{{conclusion}}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "geospatial_datacube_book_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
