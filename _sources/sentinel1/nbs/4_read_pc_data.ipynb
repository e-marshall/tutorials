{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ce46eaf7-1d78-4afe-859f-661c58ffbee1",
   "metadata": {},
   "source": [
    "# 4.4 Read Sentinel-1 RTC data from Microsoft Planetary Computer\n",
    "\n",
    "This notebook demonstrates how to access Sentinel-1 RTC imagery from [Microsoft Planetary Computer](https://planetarycomputer.microsoft.com/) using [`stackstac`](https://stackstac.readthedocs.io/en/latest/). [STAC](https://stacspec.org/en) stands for Spatio-Temporal Asset Catalog, it is a common framework to describe geospatial information and a way for data providers, developers, and users to work and exchange information efficiently. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd085da9",
   "metadata": {},
   "source": [
    "::::{tab-set}\n",
    ":::{tab-item} Outline  \n",
    "\n",
    "(content.Section_A)=\n",
    "**[A. Connect to Microsoft Planetary Computer](#a-connect-to-microsoft-planetary-computer)**\n",
    "- 1) Explore STAC metadata\n",
    "\n",
    "(content.Section_B)=\n",
    "**[B. Read data and create Xarray data cube](#b-read-data-with-xarray)**\n",
    "- 1) Create a Dask distributed cluster\n",
    "- 2) Use `stackstac` to pull queried data from Planetary Computer\n",
    "- 3) Inspect dataset\n",
    "\n",
    "(content.Section_C)= \n",
    "**[C. Visualize data](#c-visualize-data)**\n",
    "- 1) Ascending and descending pass acquisitions\n",
    "- 2) Variability over time\n",
    "- 3) Seasonal variability\n",
    "\n",
    ":::\n",
    ":::{tab-item} Learning goals\n",
    "\n",
    "#### Concepts\n",
    "- Querying large cloud-hosted dataset\n",
    "- Accessing cloud-hosted data stored as COGs (cloud-optimized GeoTIFFs)\n",
    "- Extracting and organizing metadata\n",
    "\n",
    "#### Techniques\n",
    "- Introduction to working with STAC data\n",
    "- Using `pystac_client` to query cloud-hosted datasets, observe metadata\n",
    "- Using `stackstac` to read cloud-hosted data as xarray objects\n",
    "- Using `xarray` to manipulate and organize Sentinel-1 SAR data\n",
    "- Performing grouping and reductions on `xarrray` objects\n",
    "- Visualizing `xarray` objects using `FacetGrid`\n",
    ":::\n",
    "\n",
    ":::{tab-item} Relevant Concepts\n",
    "1. [Sentinel-1 RTC imagery](../../background/4_tutorial_data.md#sentinel-1-radiometric-terrain-corrected-rtc-imagery)\n",
    "2. {term}`Spatio-temporal Asset Catalog (STAC)`\n",
    "::::"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "329bb298-9f22-47e1-afba-af9a7ef77978",
   "metadata": {
    "tags": [
     "hide-input",
     "hide-output"
    ]
   },
   "outputs": [],
   "source": [
    "%xmode minimal\n",
    "import geopandas as gpd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import planetary_computer\n",
    "from pystac_client import Client\n",
    "import rich.table\n",
    "import stackstac\n",
    "\n",
    "import s1_tools"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44cd0c50",
   "metadata": {},
   "source": [
    "{{break}}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8907c79c-b4fe-4e38-a858-60b6d731eb46",
   "metadata": {},
   "source": [
    "## A. Connect to Microsoft Planetary Computer \n",
    "\n",
    "We use the [`pystac_client`](https://pystac-client.readthedocs.io/) package to interact with and query the Microsoft Planetary Computer [Sentinel-1 RTC dataset](https://planetarycomputer.microsoft.com/dataset/group/sentinel-1). In the cell below, we will create an object called `catalog` by calling the `.open()` method of the `Client` class. This establishes a connection with the data hosted at the url provided."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5cbcbe6-62ca-4ccd-9162-d412e18ee09c",
   "metadata": {},
   "source": [
    "### 1) Explore STAC metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "065310e4-a5e1-4997-9a44-ef5936f9ed31",
   "metadata": {},
   "outputs": [],
   "source": [
    "catalog = Client.open(\"https://planetarycomputer.microsoft.com/api/stac/v1\")\n",
    "catalog"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bca010bf-ef52-4c75-8d42-88667f0af875",
   "metadata": {},
   "source": [
    "Next, define some parameters to help us query the data catalog for a specific collection, time range, and geographic area of interest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78f3adbc-296e-45de-8fcd-e5e2b8860f0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "time_range = \"2021-05-04/2022-05-21\"\n",
    "bbox = [88.214935, 27.92767, 88.302, 28.034]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cc50291-dad1-41bd-b5ff-de6dd69adc4e",
   "metadata": {},
   "source": [
    "Now, search the catalog for entries that match the specified criteria for collection (Sentinel-1 RTC), bbox (the AOI defined above) and datetime (the specified time range):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c83d0c9-a493-415c-bc52-419a51fc3fb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "search = catalog.search(collections=[\"sentinel-1-rtc\"], bbox=bbox, datetime=time_range)\n",
    "items = search.item_collection()\n",
    "len(items)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c0a6ba5-280f-459c-bf4b-1cb2516ef760",
   "metadata": {},
   "source": [
    "We've created a few more instances of `pystac_client` classes. Check out the object types below to better familiarize yourself with the STAC metadata objects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c12a334-216c-4eaf-9bdb-f106be58d97d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(type(catalog))\n",
    "print(type(search))\n",
    "print(type(items))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "450d2505-8797-456a-bd8a-97d7357ab785",
   "metadata": {},
   "source": [
    "`items` is an instance of the class `ItemCollection`; we can explore it via the embedded html interface."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3063d9fb-dd6f-4ae8-89c3-eaab540c2d50",
   "metadata": {},
   "outputs": [],
   "source": [
    "items"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8d4905f-4661-4473-87ec-c865fd29f97f",
   "metadata": {},
   "source": [
    "To make it easier to work with, we can convert  the `items` object to a dictionary, and from there, to a `geopandas.GeoDataFrame`. The metadata from within each `item` of the `ItemCollection` object is present in the `GeoDataFrame` but its easier to scan and organize this way. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e18e6e6-3487-43d3-b50d-4afd3c1d562a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = gpd.GeoDataFrame.from_features(items.to_dict(), crs=\"epsg:4326\")\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f81e193a-99b6-4deb-99e9-0988920b36a2",
   "metadata": {},
   "source": [
    "Construct a table with metadata for a single scene (ie. a single element of the list `items`). This is similar (but not identical) to the information stored in the file name and README files of the Sentinel-1 data we read from local storage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6715f677-c87f-47fa-94cb-9fb7837174cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "table = rich.table.Table(\"key\", \"value\")\n",
    "for k, v in sorted(items[0].properties.items()):\n",
    "    table.add_row(k, str(v))\n",
    "table"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad6bc1bf-5b49-4533-aea7-2862b812985c",
   "metadata": {},
   "source": [
    "We can also explore the object metadata outside of the table. Try typing `.assets`, `.links`, `.STAC_extensions` and `.properties` onto the term below. \n",
    "You can query the object programmatically for the same metadata stored in the table using dictionary syntax on the `properties` accessor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec3a354c-f6e5-46be-86ef-aca0273016e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "items[0]\n",
    "# items[0].assets\n",
    "# items[0].links\n",
    "# items[0].properties"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de05888e-e358-418f-8e4e-baf45b5eb0fe",
   "metadata": {},
   "source": [
    "Now that we'e explored the items that fit our query of the dataset and seen the metadata, let's read the data using Xarray. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1b7e318",
   "metadata": {},
   "source": [
    "## B. Read data with Xarray"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39c77646",
   "metadata": {},
   "source": [
    "### 1) Create a Dask distributed cluster"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ceaba169",
   "metadata": {},
   "source": [
    "We use [`dask.distributed`](https://distributed.dask.org/en/stable/) to parallelize operations in this notebook. Similarly to PySTAC, Dask distributed also uses a client. The dask distributed client allows us to interact with the scheduler that manages jobs across a cluster of compute resources whether they are cores on a local machine or virtual machines distributed across a cloud-compute platform. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e98cb544-66d0-4e3a-8374-a066fccc5280",
   "metadata": {},
   "outputs": [],
   "source": [
    "# give dask client a name other than 'Client'\n",
    "from dask.distributed import Client as da_Client\n",
    "\n",
    "client = da_Client(processes=False)\n",
    "print(client.dashboard_link)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29017257",
   "metadata": {},
   "source": [
    "The `client.dashboard_link` points to a dask dashboard for the client we've just initialized. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "add748dd-c81d-4e49-bfcd-78125a6d9a0d",
   "metadata": {},
   "source": [
    "### 2) Use `stackstac` to pull queried data from Planetary Computer\n",
    "\n",
    "Now that we have queried the data that is available from Microsoft Planetary Computer and inspected the metadata using `pystac`, we use `stackstac` to read the data into memory as an Xarray object. Calling `stackstac.stack()` takes a STAC `collection` and produces a lazy `xarray.DataArray` backed by Dask arrays. For more on Dask arrays see [relevant concepts](../../background/6_relevant_concepts.md)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12c95433-ad4a-4e18-93eb-108324bdd489",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(items)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c66c64ed-c149-418c-902d-8641f9075eac",
   "metadata": {},
   "source": [
    "#### *More detail on `stackstack.stac()`*\n",
    "\n",
    "In the code cell below, you can see that we pass the object `items`, a `pystac.ItemCollection` to `stackstac.stack()`. The wrapper `planetary_computer.sign()` uses Planetary Computer subscription key credentials to access the data. \n",
    "\n",
    "`stackstac` passes the metadata from the STAC collection into the Xarray object as coordinates allowing you to further organize and manipulate the object to fit your purposes. `stackstac` can also read the data in according to parameters passed during the `stack()` call. In the code cell below we pass parameters for bounding box and coordinate reference system. To specify the resolution as something other than the resolution at which its stored, pass a `resolution = ` argument. \n",
    "\n",
    ":::{note}\n",
    "During development of this notebook, an intermittent 'Broken Pipe' error occurred on this step. We believe this is upstream of any of the code used in this tutorial, so if it happens, try restarting the kernel and running the notebook again.\n",
    ":::"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ac33f88-f70d-454d-a598-bc1939409d6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "da = stackstac.stack(\n",
    "    planetary_computer.sign(items),\n",
    "    bounds_latlon=bbox,\n",
    "    epsg=32645,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce64e11b",
   "metadata": {},
   "source": [
    "Load the data into memory (this may take a few minutes):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c952965c",
   "metadata": {},
   "outputs": [],
   "source": [
    "da = da.compute()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8223da47",
   "metadata": {},
   "source": [
    "### 3) Inspect dataset\n",
    "\n",
    "Let's take a look at what `stackstac.stack()` returns."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a51d65e2",
   "metadata": {},
   "source": [
    "We have a `xr.DataArray`, meaning there is only one data variable. It has 'x','y','time' dimensions as well as a 'band' dimension. This is how the VV and VH polarization images are stored. Note that this dataset doesn't come with a layover-shadow map like the ASF processed Sentinel-1 RTC dataset. \n",
    "\n",
    "In addition, there are 39 coordinate variables that provide information about the backscatter imagery and how it was collected and processed. In addition, the object has `attrs` that describe the spatial resolution and coordinate reference information. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91f5ae2a-cbbb-4603-b6bb-b7b2092ba6d6",
   "metadata": {},
   "source": [
    "## C. Visualize data\n",
    "\n",
    "Let's do a little bit of looking around. We'll define a function to convert the backscatter pixel values from power to dB scale but we won't use it yet. This transformation applies a logarithmic scale to the data which makes visualization easier but we do not want to run any summary statistics on the dB data as it will be distorted.\n",
    "\n",
    ":::{admonition} A note on visualizing SAR data\n",
    "The measurements that we're provided in the RTC dataset are in intensity, or power, scale. Often, to visualize SAR backscatter, the data is converted from power to normalized radar cross section (the backscatter coefficient). This is in decibel (dB) units, meaning a log transform has been applied. This transformation makes it easier to visualize variability but it is important not to calculate summary statistics on log-transformed data as it will be distorted. You can read more about these concepts [here](https://hyp3-docs.asf.alaska.edu/guides/introduction_to_sar/#sar-scale).\n",
    ":::"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05a94318",
   "metadata": {},
   "outputs": [],
   "source": [
    "s1_tools.power_to_db(da.mean(dim=\"time\")).plot(\n",
    "    col=\"band\", cmap=plt.cm.Greys_r, cbar_kwargs=({\"label\": \"Backscatter (dB)\"})\n",
    ");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c6b1385",
   "metadata": {},
   "source": [
    "This plot shows mean backscatter over time of VV and VH polarizations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "868197fe-002d-491a-8503-32391c89b009",
   "metadata": {},
   "source": [
    "### 1) Ascending and descending pass acquisitions\n",
    "\n",
    "What if we wanted to look only at imagery taken during `ascending` or `descending` passes of the satellite? Because orbital direction is a non-dimensional coordinate, we need to use `.where()` instead of `.sel()` to subset the dataset according to orbital direction.\n",
    "\n",
    "For more discussion on orbital direction and the differences between ascending and descending passes, see the previous [notebook](content:orbital_dir_section)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d7e59b1-1f7d-4bf5-bec6-6c6ba7bac205",
   "metadata": {},
   "outputs": [],
   "source": [
    "da_asc = da.where(da[\"sat:orbit_state\"] == \"ascending\", drop=True)\n",
    "da_desc = da.where(da[\"sat:orbit_state\"] == \"descending\", drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53ef338b",
   "metadata": {},
   "source": [
    "Plot the mean over time of ascending and descending pass scenes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1b1e353-2375-409e-9418-448e83bacaf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "asc_min = np.array(\n",
    "    [\n",
    "        s1_tools.power_to_db(da_asc.sel(band=\"vv\").mean(dim=\"time\")).min(),\n",
    "        s1_tools.power_to_db(da_asc.sel(band=\"vh\").mean(dim=\"time\")).min(),\n",
    "    ]\n",
    ").min()\n",
    "\n",
    "asc_max = np.array(\n",
    "    [\n",
    "        s1_tools.power_to_db(da_asc.sel(band=\"vv\").mean(dim=\"time\")).max(),\n",
    "        s1_tools.power_to_db(da_asc.sel(band=\"vh\").mean(dim=\"time\")).max(),\n",
    "    ]\n",
    ").max()\n",
    "\n",
    "fig, axs = plt.subplots(ncols=2, figsize=(15, 7))\n",
    "s1_tools.power_to_db(da_asc.sel(band=\"vv\").mean(dim=\"time\")).plot(\n",
    "    cmap=plt.cm.Greys_r,\n",
    "    ax=axs[0],\n",
    "    cbar_kwargs=({\"label\": \"Backscatter (dB)\"}),\n",
    "    vmin=asc_min,\n",
    "    vmax=asc_max,\n",
    ")\n",
    "s1_tools.power_to_db(da_asc.sel(band=\"vh\").mean(dim=\"time\")).plot(\n",
    "    cmap=plt.cm.Greys_r, ax=axs[1], cbar_kwargs=({\"label\": \"Backscatter (dB)\"})\n",
    ")\n",
    "fig.suptitle(\"Mean over time of ascending scenes\")\n",
    "axs[0].set_title(\"VV\")\n",
    "axs[1].set_title(\"VH\")\n",
    "for i in range(len(axs)):\n",
    "    axs[i].tick_params(axis=\"x\", rotation=45)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fff7f698",
   "metadata": {},
   "source": [
    "Here, we're observing mean backscatter over time of both polarizations, including only ascending passes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5daec33",
   "metadata": {},
   "outputs": [],
   "source": [
    "desc_min = np.array(\n",
    "    [\n",
    "        s1_tools.power_to_db(da_asc.sel(band=\"vv\").mean(dim=\"time\")).min(),\n",
    "        s1_tools.power_to_db(da_asc.sel(band=\"vh\").mean(dim=\"time\")).min(),\n",
    "    ]\n",
    ").min()\n",
    "\n",
    "desc_max = np.array(\n",
    "    [\n",
    "        s1_tools.power_to_db(da_asc.sel(band=\"vv\").mean(dim=\"time\")).max(),\n",
    "        s1_tools.power_to_db(da_asc.sel(band=\"vh\").mean(dim=\"time\")).max(),\n",
    "    ]\n",
    ").max()\n",
    "\n",
    "fig, axs = plt.subplots(ncols=2, figsize=(15, 7))\n",
    "s1_tools.power_to_db(da_desc.sel(band=\"vv\").mean(dim=\"time\")).plot(\n",
    "    cmap=plt.cm.Greys_r,\n",
    "    ax=axs[0],\n",
    "    cbar_kwargs=({\"label\": \"Backscatter (dB)\"}),\n",
    "    vmin=desc_min,\n",
    "    vmax=desc_max,\n",
    ")\n",
    "s1_tools.power_to_db(da_desc.sel(band=\"vh\").mean(dim=\"time\")).plot(\n",
    "    cmap=plt.cm.Greys_r,\n",
    "    ax=axs[1],\n",
    "    cbar_kwargs=({\"label\": \"Backscatter (dB)\"}),\n",
    "    vmin=desc_min,\n",
    "    vmax=desc_max,\n",
    ")\n",
    "fig.suptitle(\"Mean over time of descending scenes\")\n",
    "axs[0].set_title(\"VV\")\n",
    "axs[1].set_title(\"VH\")\n",
    "for i in range(len(axs)):\n",
    "    axs[i].tick_params(axis=\"x\", rotation=45)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bd9e8c0-387d-4e7f-97f9-4d49a33a0c83",
   "metadata": {},
   "source": [
    "In this plot, we're looking at mean backscatter over time of descending passes. It looks like there is some interesting variability between the two images. What if we wanted to see how these differences persist over time?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e1845a3",
   "metadata": {},
   "source": [
    "### 2) Variability over time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab1185e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(12, 5))\n",
    "\n",
    "ax.set_title(\"Mean backscatter for VH band (red) and VV band (blue) over time\")\n",
    "s1_tools.power_to_db(da.sel(band=\"vv\").mean(dim=[\"x\", \"y\"])).plot(\n",
    "    ax=ax, linestyle=\"None\", marker=\"o\", color=\"blue\", label=\"VV\"\n",
    ")\n",
    "s1_tools.power_to_db(da.sel(band=\"vh\").mean(dim=[\"x\", \"y\"])).plot(\n",
    "    ax=ax, linestyle=\"None\", marker=\"o\", color=\"red\", label=\"VH\"\n",
    ")\n",
    "fig.legend(loc=\"center right\")\n",
    "fig.suptitle(\"Mean backscatter of VH and VV bands over time, ASC scenes\", fontsize=12, y=0.98)\n",
    "ax.set_title(None)\n",
    "ax.set_ylabel(\"Backscatter (dB)\");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7362a267-643d-48d8-a5bf-8e386527f436",
   "metadata": {},
   "source": [
    "Interesting! It looks like there is more variability in the VH band than the VV band. Over the year, there is about 4 dB variability in the VV band but over twice as much in the VH band. Chapter 2 of the [SAR handbook](https://gis1.servirglobal.net/TrainingMaterials/SAR/Chp2Content.pdf) contains information about how polarization impacts radar returns. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca08f74c",
   "metadata": {},
   "source": [
    "### 3) Seasonal variability"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5178ff37-5984-4e64-beaf-03f635db087a",
   "metadata": {},
   "source": [
    "Next, let's take a look at how backscatter values vary seasonally. To do this we will use Xarray's [groupby()](https://docs.xarray.dev/en/stable/generated/xarray.DataArray.groupby.html) and [.facetgrid](https://docs.xarray.dev/en/latest/generated/xarray.plot.FacetGrid.html) methods. We'll do this for the VV polarization. \n",
    "\n",
    ":::{note}\n",
    "This section may not work on machines with less than 8GB RAM. \n",
    ":::"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "125e874a-1952-4f3c-86b7-cf194f02409b",
   "metadata": {},
   "outputs": [],
   "source": [
    "vv_seasons_gb = da.sel(band=\"vv\").groupby(da.time.dt.season).mean()\n",
    "# add the attrs back to the season groupby object\n",
    "vv_seasons_gb.attrs = da.attrs\n",
    "# re-order the seasons\n",
    "vv_seasons_gb = vv_seasons_gb.reindex({\"season\": [\"DJF\", \"MAM\", \"JJA\", \"SON\"]})\n",
    "vv_seasons_gb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d03b63f7-20b4-4a82-b99f-ed50d3363d34",
   "metadata": {},
   "source": [
    "Use the seasons groupby object and specify the `season` dimension in the `Facetgrid` call to automatically plot mean backscatter for each season:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d218b78-556c-41ad-9484-6ca502e5c188",
   "metadata": {},
   "outputs": [],
   "source": [
    "fg_vv = s1_tools.power_to_db(vv_seasons_gb).plot(\n",
    "    col=\"season\", cmap=plt.cm.Greys_r, cbar_kwargs=({\"label\": \"Backscatter (dB)\"})\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dec7129e",
   "metadata": {},
   "source": [
    "Like in the previous [notebook](3_asf_exploratory_analysis.ipynb), we can see lower backscatter values during the summer months."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d81c6bb9-f9fe-42b9-bfd6-2e715c413c91",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "This notebook demonstrated how to access cloud-hosted data from Microsoft Planetary Computer, some basic dataset organization and preliminary exploration and visualization. The following notebook will compare the Planetary Computer dataset to the ASF dataset.\n",
    "\n",
    "We'll use IPython [storemagic](https://ipython.readthedocs.io/en/stable/config/extensions/storemagic.html) to store the object we created in this notebook, `da`, to use in the comparison. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83247a5a-773c-4905-9bab-457ebad56594",
   "metadata": {},
   "outputs": [],
   "source": [
    "%store da"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "geospatial_datacube_book_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
